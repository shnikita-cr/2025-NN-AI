{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlK56Uy7cZPE"
   },
   "source": [
    "# Вторая лабораторная\n",
    "\n",
    "Базовые методы обработки изображений.\n",
    "\n",
    "*В этом ноутбуке изначально опущены результаты исполнения кода. Рекомендуется запускать (Shift+Enter) ячейки по мере просмотра документа*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R0FyPuscZPJ",
    "ExecuteTime": {
     "start_time": "2026-01-28T16:03:40.834927Z",
     "end_time": "2026-01-28T16:03:40.862921Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UICDes60cZPL"
   },
   "source": [
    "## 1. Бинаризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNOQLS0DcZPL",
    "outputId": "9403596f-e898-40b3-dcec-3fc820238f18",
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:03:42.045389Z",
     "end_time": "2026-01-28T16:03:44.186964Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "img = mpimg.imread('./horse.jpg')\n",
    "fig, ax = try_all_threshold(rgb2gray(img), figsize=(15,15), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CeDiGqkcZPM"
   },
   "source": [
    "Посмотрим как можно улучшить результат с помощью предобработки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVkvicfrcZPN",
    "outputId": "4ad5c827-19cb-404d-a142-1ff27c6452af",
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:04:44.445799Z",
     "end_time": "2026-01-28T16:04:45.721828Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "img_blur = gaussian(img, sigma=1.5)\n",
    "\n",
    "fig, ax = try_all_threshold(rgb2gray(img_blur), figsize=(15, 15), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8isuJ0UcZPN"
   },
   "source": [
    "Рассмотрим результат бинаризации Оцу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJy5EvdbcZPO",
    "outputId": "b505433b-7185-4e01-8b66-8e8187c66954",
    "ExecuteTime": {
     "start_time": "2026-01-28T16:04:47.360445Z",
     "end_time": "2026-01-28T16:04:47.498503Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "img_blur_gray = rgb2gray(img_blur)\n",
    "thresh_otsu = threshold_otsu(img_blur_gray)\n",
    "res_otsu = img_blur_gray <= thresh_otsu\n",
    "\n",
    "plt.imshow(res_otsu, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqhXTNrdcZPP"
   },
   "source": [
    "Видно, что в целом результат неплохой, но справа от объекта осталось несколько мелких пятен.\n",
    "\n",
    "Посмотрим как можно избавиться от этих пятен:\n",
    "\n",
    "Нужные морфологические операции реализованы в библиотеке [skimage.morphology](http://scikit-image.org/docs/dev/api/skimage.morphology.html). Подключим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIrDbdiFcZPQ",
    "outputId": "ec2d39e7-0c85-4a12-8dfa-726b49286ee5",
    "ExecuteTime": {
     "start_time": "2026-01-28T16:05:21.554226Z",
     "end_time": "2026-01-28T16:05:21.694255Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_opening\n",
    "\n",
    "res_otsu_enclosed = binary_opening(res_otsu)\n",
    "\n",
    "plt.imshow(res_otsu_enclosed, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmKKmf8BcZPR"
   },
   "source": [
    "От части пятен удалось избавиться. При этом видно, что вблизи гривы маска стала значительно более гладкой, из-за применения `binary_opening`.\n",
    "\n",
    "*Если бы внутри объекта были дырки, их можно было бы закрасить по аналогии, используя метод `binary_closing(img) = binary_erosion(binary_dilation(img))`.*\n",
    "\n",
    "Проведём анализ компонент связности на маске:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onDhqzDAcZPS",
    "outputId": "7f98cfa1-ac3f-444a-8b89-bc630c0b6cf3",
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:05:23.279609Z",
     "end_time": "2026-01-28T16:05:23.501309Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "def get_largest_component(mask):\n",
    "    labels = label(mask) # разбиение маски на компоненты связности\n",
    "    props = regionprops(labels) # нахождение свойств каждой области (положение центра, площадь, bbox, интервал интенсивностей и т.д.)\n",
    "    areas = [prop.area for prop in props] # нас интересуют площади компонент связности\n",
    "\n",
    "    print(\"Значения площади для каждой компоненты связности: {}\".format(areas))\n",
    "    largest_comp_id = np.array(areas).argmax() # находим номер компоненты с максимальной площадью\n",
    "\n",
    "    print(\"labels - матрица, заполненная индексами компонент связности со значениями из множества: {}\".format(np.unique(labels)))\n",
    "    return labels == (largest_comp_id + 1) # области нумеруются с 1, поэтому надо прибавить 1 к индексу\n",
    "\n",
    "plt.imshow(get_largest_component(res_otsu_enclosed), cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7KM2hKccZPT"
   },
   "source": [
    "### Задание 1.\n",
    "\n",
    "Подберите изображение, на котором объект достаточно чётко отделим от фона. Выделите на нём объект при помощи бинаризации, морфологических операций и анализа компонент связности, по аналогии с примером выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ6FfP5acZPU"
   },
   "outputs": [],
   "source": [
    "first_image = mpimg.imread('<your image>')\n",
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVH98tu2cZPV"
   },
   "source": [
    "**Локальные методы**\n",
    "\n",
    "В случае, если объект отчётливо виден, но на изображении неравномерное освещение, полезны локальные методы.\n",
    "\n",
    "Ниже приведены изображения, содержащие локальные пороговые значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcRVBI7EcZPV",
    "outputId": "3586c8d1-827d-411f-f06a-63a34fd0ceb6",
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:05:45.239387Z",
     "end_time": "2026-01-28T16:05:46.688637Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.data import page\n",
    "from skimage.filters import threshold_local\n",
    "\n",
    "page_img = page()\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ax[0].imshow(page_img, cmap='gray')\n",
    "ax[1].imshow(threshold_local(page_img, 31, method='mean'), cmap='gray')\n",
    "ax[2].imshow(threshold_local(page_img, 31, method='gaussian'), cmap='gray')\n",
    "ax[3].imshow(threshold_local(page_img, 31, method='median'), cmap='gray')\n",
    "for i in range(4): ax[i].set_axis_off()\n",
    "\n",
    "for i, title in enumerate([\"Input\", \"Mean\", \"Gaussian\", \"Median\"]): ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-Au5GMScZPV"
   },
   "source": [
    "Как видно, локальные пороговые значения состовляют что-то вроде карты освещения. Эту карту можно можно использовать для бинаризации. *Аналогичная идея используется и просто для выравнивания освещения (Single-Scale Retinex) на изображении.*\n",
    "\n",
    "Выделим объекты с помощью полученных локальных пороговых значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca5QV8d2cZPW",
    "outputId": "1e1429b7-9a59-4cfc-9f66-9d868a4b7af1",
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:05:48.079149Z",
     "end_time": "2026-01-28T16:05:49.342936Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ax[0].imshow(page_img >= threshold_otsu(page_img), cmap='gray')\n",
    "ax[1].imshow(page_img >= threshold_local(page_img, 31, method='mean'), cmap='gray')\n",
    "ax[2].imshow(page_img >= threshold_local(page_img, 31, method='gaussian'), cmap='gray')\n",
    "ax[3].imshow(page_img >= threshold_local(page_img, 31, method='median'), cmap='gray')\n",
    "for i in range(4): ax[i].set_axis_off()\n",
    "\n",
    "for i, title in enumerate([\"Otsu\", \"Local: Mean\", \"Local: Gaussian\", \"Local: Median\"]): ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu5zKwr9cZPW"
   },
   "source": [
    "### Задание 2.\n",
    "\n",
    "Подберите изображение, на котором обычная бинаризация даёт плохие результаты, когда как локальная позволяет получить результаты гораздо лучше. Найдите наиболее подходящие параметры метода `threshold_local`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my4p3rGycZPW"
   },
   "outputs": [],
   "source": [
    "img_local = mpimg.imread('<your image>')\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ax[0].imshow(img_local >= threshold_otsu(img_local), cmap='gray')\n",
    "ax[1].imshow(img_local >= threshold_local(img_local, 31, method='mean'), cmap='gray')\n",
    "ax[2].imshow(img_local >= threshold_local(img_local, 31, method='gaussian'), cmap='gray')\n",
    "ax[3].imshow(img_local >= threshold_local(img_local, 31, method='median'), cmap='gray')\n",
    "\n",
    "for i, title in enumerate([\"Otsu\", \"Local: Mean\", \"Local: Gaussian\", \"Local: Median\"]): ax[i].set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jW4Hti16cZPX"
   },
   "source": [
    "## 2. Представления изображений\n",
    "\n",
    "Посмотрим на преобразование Фурье:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmTkoGVecZPX",
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:06:14.970557Z",
     "end_time": "2026-01-28T16:06:16.174247Z"
    }
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('cube.jpg')\n",
    "\n",
    "f = np.fft.fft2(rgb2gray(img)) # вычисляем 2D-FFT для изображения\n",
    "fshift = np.fft.fftshift(f)    # свдигаем нулевую частоту в центр\n",
    "spectrum = 100 * np.log(np.abs(fshift))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].set_title('Input Image')\n",
    "ax[1].set_title('Magnitude Spectrum (Shift + Log)')\n",
    "ax[2].set_title('Reconstructed image')\n",
    "\n",
    "ax[0].imshow(img, cmap = 'gray')\n",
    "ax[1].imshow(spectrum, cmap = 'gray')\n",
    "\n",
    "transformed_fshift = fshift.copy()\n",
    "transformed_fshift[0:400, 0:200] = 0 # удалим куски, не содержащие светлых прямых на спектре, это не повлияет на рёбра куба\n",
    "transformed_fshift[600:900, 800:1000] = 0\n",
    "inv = np.fft.ifft2(np.fft.ifftshift(transformed_fshift)).real # восстановим изображение обратным преобразованием\n",
    "ax[2].imshow(inv, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28kI3TH5cZPX"
   },
   "source": [
    "Видно, что прямые на спектре соответствуют прямым на исходном изображении.\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "Подберите изображение, чтобы на его спектре была окружность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_aBYWRbcZPY"
   },
   "outputs": [],
   "source": [
    "img_2 = mpimg.imread('<your image>')\n",
    "\n",
    "plt.imshow(100 * np.log(np.abs(np.fft.fftshift(np.fft.fft2(rgb2gray(img_2))))), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MycSQ7dcZPY"
   },
   "source": [
    "### Задание 4.\n",
    "\n",
    "Достаточно часто возникает задача распознавания геометрических объектов (прямых, окружностей и т.п.)\n",
    "\n",
    "Найдём границы куба с помощью преобразования Хаффа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHoNJ5LycZPY",
    "ExecuteTime": {
     "start_time": "2026-01-28T16:06:29.959699Z",
     "end_time": "2026-01-28T16:06:30.845610Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import (hough_line, hough_line_peaks,\n",
    "                               probabilistic_hough_line)\n",
    "from skimage.feature import canny\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "def show_hough_transform(image):\n",
    "    h, theta, d = hough_line(canny(image)) # вычисляем преобразование Хаффа от границ изображения\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    ax[0].imshow(image, cmap=cm.gray)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].set_axis_off()\n",
    "\n",
    "    ax[1].imshow(np.log(1 + h),\n",
    "                 extent=[np.rad2deg(theta[-1]), np.rad2deg(theta[0]), d[-1], d[0]],\n",
    "                 cmap='gray', aspect=1/20)\n",
    "    ax[1].set_title('Hough transform')\n",
    "    ax[1].set_xlabel('Angles (degrees)')\n",
    "    ax[1].set_ylabel('Distance (pixels)')\n",
    "\n",
    "    ax[2].imshow(image, cmap=cm.gray)\n",
    "    for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "        y0 = (dist - 0 * np.cos(angle)) / np.sin(angle)\n",
    "        y1 = (dist - image.shape[1] * np.cos(angle)) / np.sin(angle)\n",
    "        ax[2].plot((0, image.shape[1]), (y0, y1), '-r')\n",
    "    ax[2].set_xlim((0, image.shape[1]))\n",
    "    ax[2].set_ylim((image.shape[0], 0))\n",
    "    ax[2].set_axis_off()\n",
    "    ax[2].set_title('Detected lines')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "cube = rgb2gray(imread('./cube.jpg'))\n",
    "show_hough_transform(cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Us6FzRI_cZPY"
   },
   "source": [
    "**Задание:**\n",
    "\n",
    "Подберите изображение, на котором с помощью преобразования Хафа можно найти несколько прямых:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdnRNuuJcZPZ"
   },
   "outputs": [],
   "source": [
    "image_with_lines = rgb2gray(imread('<your image>'))\n",
    "\n",
    "show_hough_transform(image_with_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZVHLORhcZPZ"
   },
   "source": [
    "## Поиск границ\n",
    "\n",
    "Часто возникает задача поиска границ на изображении: они могут быть использованы для распознавания образов (Object Detection), сегментации и классификации изображений. Так, в предыдущей задаче поиск линий осуществлялся именно на карте границ, а не на исходном изображении.\n",
    "\n",
    "Посмотрим на различные фильтры, помогающие при выделении границ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiOSMCfMcZPZ",
    "ExecuteTime": {
     "start_time": "2026-01-28T16:06:50.696503Z",
     "end_time": "2026-01-28T16:06:51.230425Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage.feature import canny\n",
    "\n",
    "matchbox = rgb2gray(mpimg.imread('matchbox.jpg')) # детекторы границ по умолчанию работают с одним каналом\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 6))\n",
    "ax[0, 0].imshow(matchbox, cmap='gray')\n",
    "ax[0, 1].imshow(roberts(matchbox), cmap='gray')\n",
    "ax[0, 2].imshow(sobel(matchbox), cmap='gray')\n",
    "ax[1, 0].imshow(scharr(matchbox), cmap='gray')\n",
    "ax[1, 1].imshow(prewitt(matchbox), cmap='gray')\n",
    "ax[1, 2].imshow(canny(matchbox), cmap='gray')\n",
    "for i, title in enumerate([\"Input\", \"Roberts\", \"Sobel\", \"Scharr\", \"Prewitt\", \"Canny\"]): ax.flatten()[i].set_title(title)\n",
    "for i in range(6): ax.flatten()[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qv_ugGRcZPZ"
   },
   "source": [
    "Фильтры Roberts, Sobel, Scharr, Prewitt вычисляют различные аппроксимации модуля градиента.\n",
    "\n",
    "Детектор Canny - находит тонкие границы, соответствующие локальным максимумам модуля градиента. Поэтому зачастую граница состоит из набора коротких кривых. И для edge-based сегментации (выделения полного контура объекта) с помощью детектора Canny требуется подбирать параметры.\n",
    "\n",
    "Выделим спичечный коробок на изображении двумя способами: с помощью карты границ, полученной детектором Canny, и с помощью так называемой region-based сегментации - методом [водораздела](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29), применяя аппроксимацию модуля градиента Собеля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8g3-Fy0BcZPZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.morphology import binary_closing, binary_erosion\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 6))\n",
    "\n",
    "canny_edge_map = binary_closing(canny(matchbox, sigma=1))\n",
    "matchbox_edge_segmentation = binary_fill_holes(canny_edge_map)\n",
    "\n",
    "ax[0].imshow(canny_edge_map, cmap='gray')\n",
    "ax[1].imshow(label2rgb(matchbox_edge_segmentation, image=matchbox))\n",
    "\n",
    "# поставим маркеры фона и объекта\n",
    "markers = np.zeros_like(matchbox)\n",
    "markers[0:10, 0:10] = 1 # маркеры фона\n",
    "markers[binary_erosion(canny_edge_map) > 0] = 2 # маркеры объекта - точки, находящиеся заведомо внутри\n",
    "\n",
    "sobel_gradient = sobel(matchbox)\n",
    "matchbox_region_segmentation = watershed(sobel_gradient, markers)\n",
    "\n",
    "ax[2].imshow(sobel_gradient, cmap='gray')\n",
    "ax[3].imshow(label2rgb(matchbox_region_segmentation, image=matchbox))\n",
    "\n",
    "for i, title in enumerate([\"Canny dilated edges\", \"Edge-based segmentation\", \"Gradient magnitude\", \"Region-based segmentation\"]): ax[i].set_title(title)\n",
    "for i in range(3): ax[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZVqtynpcZPa"
   },
   "source": [
    "Визуально оба метода справились достаточно хорошо, но у каждого есть свои недостатки и преимущества:\n",
    "* edge-based сегментация в данном случае дала не совсем корректный результат (в маску вошли две лишние кривые, идущие по тени), при этом вручную были подобраны параметры фильтра и ядра дилатации;\n",
    "* для region-based пришлось вручную задать маркеры объекта - на практике такой информации могло бы и не быть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uBV_28RcZPa"
   },
   "source": [
    "### Задание 5.\n",
    "* Подберите изображение, на котором можно выделить объект первым подходом (с помощью карты границ). При этом на изображении должен быть неоднородный фон;\n",
    "* Найдите параметры детектора границ и морфологических операций, чтобы получить максимально точную маску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFdlKouVcZPa"
   },
   "outputs": [],
   "source": [
    "easy_to_segment = rgb2gray(mpimg.imread('<your image>'))\n",
    "\n",
    "my_edge_map = binary_closing(canny(easy_to_segment, sigma=1), selem=np.ones((4, 4)))\n",
    "my_edge_segmentation = binary_fill_holes(my_edge_map)\n",
    "\n",
    "plt.imshow(label2rgb(my_edge_segmentation, image=easy_to_segment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVbvPKtwcZPa"
   },
   "source": [
    "## Особые точки \n",
    "\n",
    "Особые точки - один из основных механизмов извлечения признаков для распознавания образов и локализации заданного объекта на изображении.\n",
    "\n",
    "Существует несколько типов особых точек и дескрипторов:\n",
    "* инвариантные к сдвигу, масштабированию и повороту - SIFT, SURF, FAST;\n",
    "* инвариантные к масштабированию, но не к повороту - U-SURF;\n",
    "* не инвариантные к масштабированию - Blob (обычно дескрипторы описывают соответствующие точки, но с разным значением радиуса);\n",
    "* и другие.\n",
    "\n",
    "Посмотрим на результаты работы различных детекторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHdQHZcWcZPb",
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:07:37.907888Z",
     "end_time": "2026-01-28T16:07:39.581745Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.feature import corner_harris, corner_peaks, corner_fast, corner_subpix\n",
    "from skimage.transform import warp, AffineTransform\n",
    "\n",
    "basketball = rgb2gray(mpimg.imread(\"basketball.jpg\"))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].set_title('Image')\n",
    "ax[0].imshow(basketball, cmap='gray')\n",
    "\n",
    "# corner_harris возвращает матрицу, в которой максимумы соответствуют особым точкам\n",
    "# поэтому чтобы извлечь координаты надо вызвать corner_peaks\n",
    "basketball_harris = corner_peaks(corner_harris(basketball))\n",
    "ax[1].set_title('Harris')\n",
    "ax[1].imshow(basketball, cmap='gray')\n",
    "ax[1].plot(basketball_harris[:, 1], basketball_harris[:, 0], '+b', markersize=2)\n",
    "\n",
    "basketball_fast = corner_peaks(corner_fast(basketball))\n",
    "ax[2].set_title('FAST')\n",
    "ax[2].imshow(basketball, cmap='gray')\n",
    "ax[2].plot(basketball_fast[:, 1], basketball_fast[:, 0], '+b', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsuBoL23cZPb"
   },
   "source": [
    "Решим задачу стабилизации видеоряда: дана последовательность изображений (для простоты - два), требуется сделать так, чтобы объект занимал одно и то же положение в кадре.\n",
    "\n",
    "Сначала сгенерируем данные искусственным образом: пусть камера немного повернулась против часовой стрелки и сдвинулась вверх.\n",
    "Получим новую картинку поворотом старой на 3 градуса и сдвигом на 20 пикселей вправо и вниз, и посмотрим на особые точки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq3B_a8PcZPb",
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2026-01-28T16:07:47.382545Z",
     "end_time": "2026-01-28T16:07:49.419620Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import warp, AffineTransform\n",
    "\n",
    "tform = AffineTransform(rotation=np.deg2rad(3), translation=(20, 20))\n",
    "basketball2 = warp(basketball, tform.inverse, output_shape=basketball.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].imshow(basketball2, cmap='gray')\n",
    "\n",
    "basketball2_harris = corner_peaks(corner_harris(basketball2))\n",
    "ax[1].imshow(basketball2, cmap='gray')\n",
    "ax[1].plot(basketball2_harris[:, 1], basketball2_harris[:, 0], '+b', markersize=2)\n",
    "\n",
    "basketball2_fast = corner_peaks(corner_fast(basketball2))\n",
    "ax[2].imshow(basketball2, cmap='gray')\n",
    "ax[2].plot(basketball2_fast[:, 1], basketball2_fast[:, 0], '+b', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDEfkEybcZPb"
   },
   "source": [
    "Видно, что часть особых точек находится в тех же местах объекта, где и была до поворота.\n",
    "\n",
    "Найдём дескрипторы особых точек исходной и искажённой картинок, и сдвинем вторую картинку, чтобы она занимала исходное положение.\n",
    "\n",
    "Для этого воспользуемся *ORB* - детектором (*Oriented FAST and rotated BRIEF*) и методом RANSAC для поиска аффинного преобразования, после чего применим обратное аффинное преобразование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lBWfti1cZPc",
    "ExecuteTime": {
     "start_time": "2026-01-28T16:07:52.736089Z",
     "end_time": "2026-01-28T16:07:56.338271Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.feature import match_descriptors, ORB\n",
    "from skimage.measure import ransac\n",
    "\n",
    "orb = ORB()\n",
    "orb.detect_and_extract(basketball)\n",
    "\n",
    "orb2 = ORB()\n",
    "orb2.detect_and_extract(basketball2)\n",
    "\n",
    "basketball_match = match_descriptors(orb.descriptors, orb2.descriptors, cross_check=True)\n",
    "\n",
    "src = orb.keypoints[basketball_match[:, 0]]\n",
    "dst = orb2.keypoints[basketball_match[:, 1]]\n",
    "    \n",
    "estimated_transform, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n",
    "                               residual_threshold=2, max_trials=1000)\n",
    "\n",
    "basketball3_stab = warp(basketball2, AffineTransform(translation=estimated_transform.translation,\n",
    "                                                     rotation=-estimated_transform.rotation),\n",
    "                        output_shape=basketball2.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].imshow(basketball, cmap='gray')\n",
    "ax[1].imshow(basketball3_stab, cmap='gray')\n",
    "ax[2].imshow(basketball, cmap='gray', alpha=0.5)\n",
    "ax[2].imshow(basketball3_stab, cmap='gray', alpha=0.5)\n",
    "\n",
    "for i, title in enumerate(['1 кадр', 'Стабилизированный 2 кадр', 'Наложение']): ax[i].set_title(title)\n",
    "\n",
    "print(f\"Оценка сдвига: {estimated_transform.translation}\")\n",
    "print(f\"Оценка поворота: {np.rad2deg(estimated_transform.rotation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf6pd2cqcZPc"
   },
   "source": [
    "Видно, что подход работает достаточно хорошо, поэтому его часто применяют для решения аналогичных задач на практике. Существуют и другие подходы к решению данной задачи: оценка оптического потока (Optical Flow), и сопоставление с шаблоном с помощью преобразования Фурье."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBglMtCScZPc"
   },
   "source": [
    "Точно такую же технику можно использовать для решения задачи поиска гомографии, в частности - проективного преобразования, то есть для поиска отображения, преобразующего шаблонное изображение (например, qr-код) в объект на другом заданном изображении (снимке с камеры). С помощью найденной (или не найденной) гомографии можно установить есть ли объект на изображении, где он находится; исправить перспективу; отрендерить 3d-объект, чтобы он реалистично вписывался в сцену (AR), и другое."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
