{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhqp2azsNEfC"
   },
   "source": [
    "## Случайные леса / Random Forest / RF\n",
    "\n",
    "Основная идея - по имеющимся признакам принять решение. Например, если нам необходимо отличить млекопитающего животного от пресмыкающего, то основным признаком отбора будет - кормление детеныша молоком. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xvi3ecZ1NEfI"
   },
   "source": [
    "### Универсальность метода\n",
    "\n",
    "Универсальность метода заключается в том, что он подходит для решения любой задачи, кроме работы с изображениями. Мы можем использовать его для решения задачи регрессии, классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBOCl5hMNEfK"
   },
   "source": [
    "### Принятие итогового решения\n",
    "\n",
    "Случайные леса - это использование М деревьев принятия решений для разных данных из одного набора данных. После выполнения дерева принятия решения мы получаем М ответов. После этого нужно М решений свести к одному. Для решения задачи регрессии М ответов усредняют. Для решение задачи классификации используют голосование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P45g0TOyNEfK"
   },
   "source": [
    "### Реализация\n",
    "В библиотеке scikit-learn есть реализация RF. Мы сегодня рассмотрим решение задачи классификации с помощью нее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCsWIX3WNEfL"
   },
   "outputs": [],
   "source": [
    "# Подключение библиотеки для работы со случайными лесами\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdRLsWZ0NEfN"
   },
   "source": [
    "1. Инициализация данных и предсказание класса, к которому относится новая точка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3A6Lj_GINEfO",
    "outputId": "96919b32-543e-4be9-8775-43f216f86883"
   },
   "outputs": [],
   "source": [
    "x_train = [ [1, 2], [5, 6], [3, 4],\n",
    "           [7, 8], [-1, 2], [-5, 6],\n",
    "           [-3, 4], [-7, 8], [0, 0]] # точки исходного множества/набор данных из точек\n",
    "\n",
    "y_train = [1, 1, 1, 1, 0, 0, 0, 0, 1] # классы для каждой точки из x_train\n",
    "\n",
    "# создание деревьев\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "# обучение\n",
    "clf_rf.fit(x_train, y_train)\n",
    "\n",
    "# предсказание класса для новой точки\n",
    "result = clf_rf.predict([[2, 2]])\n",
    "\n",
    "print(result)  # это предсказанный класс\n",
    "print(clf_rf.predict_proba([[2, 2]]))  # вероятности по классам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvbWQ9SwNEfP"
   },
   "source": [
    "### Описание функции RandomForestClassifier()\n",
    "\n",
    "У этой функции очень много параметров, которые можно изменять, задавать самостоятельно. При этом будет изменяться результат обучения, поэтому будет изменяться и качество решения. Подбор параметров для обучения является сложной задачей.\n",
    "\n",
    "RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, max_features='auto', min_impurity_split=None,  warm_start=False)\n",
    "\n",
    "Мы разберем некоторые параметры. Вы можете при этом менять все, что посчитаете нужным.\n",
    "\n",
    "1. n_estimators (целое число/int) - количество деревьев в лесу. По умолчанию == 100\n",
    "\n",
    "2. max_depth (целое число/int или None) - максимальная глубина дерева. Обозначает сколько ярусов будет у дерева. Если Вы указываете None, то дерево будет расширяться вниз, пока такое возможно, то есть пока не будут рассмотрены все возможные признаки. По умолчанию == None\n",
    "\n",
    "3. min_samples_split (целое число/int) - минимальное число данных для разбиения дерева и оценки признака. По умолчанию == 2\n",
    "\n",
    "4. max_features (строка/string) - функция определения количества значимых признаков. Возможные варианты: auto/sqrt/log2. Если у вас n признаков в наборе данных, то при max_features == 'sqrt' число значимых признаков будет равно sqrt(n). По умолчанию == auto\n",
    "\n",
    "5. min_impurity_split (вещественное число/float) - пороговое/минимальное значение постановки условия для признака. По умолчанию == None\n",
    "\n",
    "6. warm_start (bool/true or false) - флаг на использование дерева для предыдущего набора данных. Если == True, то для текущего набора данных будет изменяться предыдущего (преддущее дерево сохраняется).  Если == False, то построение дерева происходит самостоятельно\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vkLs_GDNEfR"
   },
   "source": [
    "Теперь необходимо разбить данные на 2 части: для обучения/построения деревьев и для проверки/тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpGq2oxUNEfR",
    "outputId": "0696a82d-3b92-4439-f3d0-d6056766d9c9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "print(X_test, Y_test)  # при каждом запуске деление будет разным\n",
    "print(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jEdgmKYNEfS"
   },
   "source": [
    "### Задание 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZqTIoj_NEfT"
   },
   "source": [
    "1.1 Постройте случайный лес для X_train, Y_train с параметрами по умолчанию. И выведите результат обучения для X_test, Y_test. Необходимый код написан выше.\n",
    "\n",
    "1.2 Посчитайте точность вашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUK3k8lgNEfT"
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5mWi8m9NEfT"
   },
   "source": [
    "### Задание 2.\n",
    "Подберите параметры для построения случайных лесов, чтобы решение стало лучше, если это возможно. Потому что при дефолтных параметрах может получится наилучшая модель для этих данных. То есть Вам необходимо создать еще случайные леса с другими параметрами, так, чтобы точность стала больше, чем у предыдущего решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVkZaaO_NEfU",
    "outputId": "ed77988d-4af8-4eb7-ee61-aae9089b39ae"
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiiBf_wMNEfU"
   },
   "source": [
    "### Автоматический поиск параметров\n",
    "\n",
    "С помощью функции GridSearchCV можно найти оптимальные гиперпараметры для модели: например, напаметр k в методе ближайших соседей, число скрытых слоев в нейронных сетях. GridSearchCV – это очень мощный инструмент для автоматического подбирания параметров для моделей машинного обучения. GridSearchCV находит наилучшие параметры путем обычного перебора: он создает модель для каждой возможной комбинации параметров. Важно отметить, что такой подход может быть весьма времязатратным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "brMF9ELYNEfU",
    "outputId": "abcab3fb-0343-4dd3-b4cd-fa8d434199c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Задаем сетку, которую будем перебирать\n",
    "grid_parameter = { \n",
    "    'n_estimators': [10,20,30,40,50,100],\n",
    "    'max_depth': [10,20,100],\n",
    "}\n",
    "\n",
    "clf =  RandomForestClassifier()\n",
    "grid_search = GridSearchCV(clf, grid_parameter) # передаем классификатор и параметры, из которых будем выбирать\n",
    "grid_search.fit(X_train, Y_train)\n",
    "clf_best = grid_search.best_estimator_\n",
    "print('Best params = ', clf_best.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6NDypo4NEfV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
