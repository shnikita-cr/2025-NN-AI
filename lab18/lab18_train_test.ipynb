{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.178139Z",
     "end_time": "2026-02-11T20:21:44.246129Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# 1. Configuration and Data Loading\n",
    "BATCH_SIZE = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize with MNIST mean (0.1307) and std (0.3081)\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.194128Z",
     "end_time": "2026-02-11T20:21:44.246129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Download and load training data\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Download and load test data\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.206141Z",
     "end_time": "2026-02-11T20:21:44.262182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.266186Z",
     "end_time": "2026-02-11T20:21:44.302191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. Define the Neural Network Model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)  #26 26\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)  # 13 13\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)  #11 11\n",
    "        # self.pool2 = nn.AdaptiveAvgPool2d(output_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.fc3 = nn.Linear(16 * 3 * 3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input image from 28x28 to a 784-element vector\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 16 * 3 * 3)\n",
    "        x = self.fc3(x)\n",
    "        # Apply log softmax for the final output (often used with NLLLoss, which is part of CrossEntropyLoss)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = SimpleNN().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.282191Z",
     "end_time": "2026-02-11T20:21:44.318192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. Define Loss and Optimizer\n",
    "criterion = nn.NLLLoss()  # Negative Log-Likelihood Loss (suitable for log_softmax output)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.294190Z",
     "end_time": "2026-02-11T20:21:44.318192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nSimpleNN                                 --\n├─Conv2d: 1-1                            80\n├─MaxPool2d: 1-2                         --\n├─Conv2d: 1-3                            1,168\n├─AdaptiveAvgPool2d: 1-4                 --\n├─Linear: 1-5                            1,450\n=================================================================\nTotal params: 2,698\nTrainable params: 2,698\nNon-trainable params: 0\n================================================================="
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:23:11.690514Z",
     "end_time": "2026-02-11T20:23:11.706141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "writer = SummaryWriter(f'runs/init_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:21:44.322191Z",
     "end_time": "2026-02-11T20:21:44.378195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2/5 [25600/60000 (43%)]\tLoss: 0.152865\n",
      "Train Epoch: 2/5 [32000/60000 (53%)]\tLoss: 0.079841\n",
      "Train Epoch: 2/5 [38400/60000 (64%)]\tLoss: 0.162038\n",
      "Train Epoch: 2/5 [44800/60000 (75%)]\tLoss: 0.097246\n",
      "Train Epoch: 2/5 [51200/60000 (85%)]\tLoss: 0.119199\n",
      "Train Epoch: 2/5 [57600/60000 (96%)]\tLoss: 0.052596\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.150450\n",
      "Train Epoch: 3/5 [6400/60000 (11%)]\tLoss: 0.050109\n",
      "Train Epoch: 3/5 [12800/60000 (21%)]\tLoss: 0.048268\n",
      "Train Epoch: 3/5 [19200/60000 (32%)]\tLoss: 0.121533\n",
      "Train Epoch: 3/5 [25600/60000 (43%)]\tLoss: 0.135786\n",
      "Train Epoch: 3/5 [32000/60000 (53%)]\tLoss: 0.086203\n",
      "Train Epoch: 3/5 [38400/60000 (64%)]\tLoss: 0.131176\n",
      "Train Epoch: 3/5 [44800/60000 (75%)]\tLoss: 0.148006\n",
      "Train Epoch: 3/5 [51200/60000 (85%)]\tLoss: 0.088567\n",
      "Train Epoch: 3/5 [57600/60000 (96%)]\tLoss: 0.043053\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.052097\n",
      "Train Epoch: 4/5 [6400/60000 (11%)]\tLoss: 0.106025\n",
      "Train Epoch: 4/5 [12800/60000 (21%)]\tLoss: 0.051528\n",
      "Train Epoch: 4/5 [19200/60000 (32%)]\tLoss: 0.094203\n",
      "Train Epoch: 4/5 [25600/60000 (43%)]\tLoss: 0.151293\n",
      "Train Epoch: 4/5 [32000/60000 (53%)]\tLoss: 0.057672\n",
      "Train Epoch: 4/5 [38400/60000 (64%)]\tLoss: 0.075243\n",
      "Train Epoch: 4/5 [44800/60000 (75%)]\tLoss: 0.198358\n",
      "Train Epoch: 4/5 [51200/60000 (85%)]\tLoss: 0.017911\n",
      "Train Epoch: 4/5 [57600/60000 (96%)]\tLoss: 0.020973\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.137749\n",
      "Train Epoch: 5/5 [6400/60000 (11%)]\tLoss: 0.102300\n",
      "Train Epoch: 5/5 [12800/60000 (21%)]\tLoss: 0.062071\n",
      "Train Epoch: 5/5 [19200/60000 (32%)]\tLoss: 0.090541\n",
      "Train Epoch: 5/5 [25600/60000 (43%)]\tLoss: 0.143444\n",
      "Train Epoch: 5/5 [32000/60000 (53%)]\tLoss: 0.075814\n",
      "Train Epoch: 5/5 [38400/60000 (64%)]\tLoss: 0.080430\n",
      "Train Epoch: 5/5 [44800/60000 (75%)]\tLoss: 0.038330\n",
      "Train Epoch: 5/5 [51200/60000 (85%)]\tLoss: 0.113578\n",
      "Train Epoch: 5/5 [57600/60000 (96%)]\tLoss: 0.091317\n"
     ]
    }
   ],
   "source": [
    "# 4. Training Loop\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = criterion(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass (calculate gradients)\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch + 1}/{NUM_EPOCHS} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:22:05.188420Z",
     "end_time": "2026-02-11T20:22:59.925733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleNN(\n  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n  (pool2): AdaptiveAvgPool2d(output_size=(3, 3))\n  (fc3): Linear(in_features=144, out_features=10, bias=True)\n)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:22:59.925733Z",
     "end_time": "2026-02-11T20:22:59.946050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleNN(\n  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n  (pool2): AdaptiveAvgPool2d(output_size=(3, 3))\n  (fc3): Linear(in_features=144, out_features=10, bias=True)\n)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:22:59.946050Z",
     "end_time": "2026-02-11T20:23:00.004798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tensorboard --logdir=runs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:22:59.966270Z",
     "end_time": "2026-02-11T20:23:00.017003Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0872, Accuracy: 9744/10000 (97.44%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Testing the Model\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "      f'({accuracy:.2f}%)\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:22:59.986565Z",
     "end_time": "2026-02-11T20:23:02.049493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Save the model (optional)\n",
    "torch.save(model.state_dict(), \"mnist_simple_nn.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:23:02.049493Z",
     "end_time": "2026-02-11T20:23:02.087898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:23:02.069721Z",
     "end_time": "2026-02-11T20:23:02.100097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def export_onnx(model, onnx_path=\"dynamic_cnn.onnx\"):\n",
    "    dummy = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy,\n",
    "            onnx_path,\n",
    "            opset_version=18,\n",
    "            dynamo=False,\n",
    "            export_params=True,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"output\"],\n",
    "            dynamic_axes={\n",
    "                \"input\": {0: \"batch\", 2: \"height\", 3: \"width\"},\n",
    "                \"output\": {0: \"batch\"},\n",
    "            },\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:23:02.089939Z",
     "end_time": "2026-02-11T20:23:02.110214Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\3476701642.py:5: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "ename": "SymbolicValueError",
     "evalue": "Unsupported: ONNX export of operator adaptive_avg_pool2d, input size not accessible. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues  [Caused by the value 'input.4 defined in (%input.4 : Float(*, 16, *, *, strides=[250000, 15625, 125, 1], requires_grad=0, device=cpu) = onnx::Relu(%19), scope: __main__.SimpleNN:: # D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1697:0\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Relu'.] \n    (node defined in D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\functional.py(1697): relu\nC:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\666256591.py(20): forward\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1765): _slow_forward\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1786): _call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1775): _wrapped_call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\jit\\_trace.py(129): wrapper\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\jit\\_trace.py(138): forward\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1786): _call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1775): _wrapped_call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\jit\\_trace.py(1403): _get_trace_graph\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(898): _trace_and_get_graph_from_model\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(991): _create_jit_graph\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(1107): _model_to_graph\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(1507): _export\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(549): export\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\__init__.py(343): export\nC:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\3476701642.py(5): export_onnx\nC:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\1986237680.py(2): <module>\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3579): run_code\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3519): run_ast_nodes\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3336): run_cell_async\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py(128): _pseudo_sync_runner\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3132): _run_cell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3077): run_cell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py(577): run_cell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py(455): do_execute\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(767): execute_request\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py(368): execute_request\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(400): dispatch_shell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(508): process_one\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(519): dispatch_queue\nC:\\Program Files\\Python310\\lib\\asyncio\\events.py(80): _run\nC:\\Program Files\\Python310\\lib\\asyncio\\base_events.py(1881): _run_once\nC:\\Program Files\\Python310\\lib\\asyncio\\base_events.py(595): run_forever\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py(211): start\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py(739): start\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel_launcher.py(18): <module>\nC:\\Program Files\\Python310\\lib\\runpy.py(86): _run_code\nC:\\Program Files\\Python310\\lib\\runpy.py(196): _run_module_as_main\n)\n\n    Inputs:\n        #0: 19 defined in (%19 : Float(*, 16, *, *, strides=[250000, 15625, 125, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%input, %conv2.weight, %conv2.bias), scope: __main__.SimpleNN::/torch.nn.modules.conv.Conv2d::conv2 # D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:543:0\n    )  (type 'Tensor')\n    Outputs:\n        #0: input.4 defined in (%input.4 : Float(*, 16, *, *, strides=[250000, 15625, 125, 1], requires_grad=0, device=cpu) = onnx::Relu(%19), scope: __main__.SimpleNN:: # D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1697:0\n    )  (type 'Tensor')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSymbolicValueError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m onnx_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mexport_onnx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monnx_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[41], line 5\u001B[0m, in \u001B[0;36mexport_onnx\u001B[1;34m(model, onnx_path)\u001B[0m\n\u001B[0;32m      2\u001B[0m dummy \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39minference_mode():\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdummy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43monnx_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m18\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mheight\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwidth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\__init__.py:343\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dynamic_shapes:\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    339\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe exporter only supports dynamic shapes \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    340\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    341\u001B[0m     )\n\u001B[1;32m--> 343\u001B[0m \u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mautograd_inlining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautograd_inlining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py:549\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001B[0m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    547\u001B[0m     args \u001B[38;5;241m=\u001B[39m args \u001B[38;5;241m+\u001B[39m (kwargs,)\n\u001B[1;32m--> 549\u001B[0m \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    552\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    553\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    557\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    558\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    559\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    561\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    562\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mautograd_inlining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautograd_inlining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py:1507\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001B[0m\n\u001B[0;32m   1504\u001B[0m     dynamic_axes \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1505\u001B[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001B[1;32m-> 1507\u001B[0m graph, params_dict, torch_out \u001B[38;5;241m=\u001B[39m \u001B[43m_model_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1510\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1512\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1513\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1514\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_do_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1515\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1518\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1520\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m custom_opsets \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1521\u001B[0m     custom_opsets \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py:1111\u001B[0m, in \u001B[0;36m_model_to_graph\u001B[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001B[0m\n\u001B[0;32m   1108\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m _get_named_param_dict(graph, params)\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1111\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[43m_optimize_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1112\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1113\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_disable_torch_constant_prop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_disable_torch_constant_prop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1122\u001B[0m     _C\u001B[38;5;241m.\u001B[39m_jit_onnx_log(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch IR graph at exception: \u001B[39m\u001B[38;5;124m\"\u001B[39m, graph)\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py:686\u001B[0m, in \u001B[0;36m_optimize_graph\u001B[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001B[0m\n\u001B[0;32m    683\u001B[0m     _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001B[0;32m    684\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_lint(graph)\n\u001B[1;32m--> 686\u001B[0m graph \u001B[38;5;241m=\u001B[39m \u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jit_pass_onnx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    687\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_lint(graph)\n\u001B[0;32m    688\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_lint(graph)\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py:1776\u001B[0m, in \u001B[0;36m_run_symbolic_function\u001B[1;34m(graph, block, node, inputs, env, values_in_env, new_nodes, operator_export_type)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m symbolic_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1772\u001B[0m         \u001B[38;5;66;03m# TODO Wrap almost identical attrs assignment or comment the difference.\u001B[39;00m\n\u001B[0;32m   1773\u001B[0m         attrs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1774\u001B[0m             k: symbolic_helper\u001B[38;5;241m.\u001B[39m_node_get(node, k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39mattributeNames()\n\u001B[0;32m   1775\u001B[0m         }\n\u001B[1;32m-> 1776\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m symbolic_fn(graph_context, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mattrs)\n\u001B[0;32m   1778\u001B[0m attrs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1779\u001B[0m     k \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m node\u001B[38;5;241m.\u001B[39mkindOf(k)[\u001B[38;5;241m0\u001B[39m]: symbolic_helper\u001B[38;5;241m.\u001B[39m_node_get(node, k)\n\u001B[0;32m   1780\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39mattributeNames()\n\u001B[0;32m   1781\u001B[0m }\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m namespace \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnx\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1783\u001B[0m     \u001B[38;5;66;03m# Clone node to trigger ONNX shape inference\u001B[39;00m\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\symbolic_helper.py:466\u001B[0m, in \u001B[0;36mquantized_args.<locals>.decorator.<locals>.wrapper\u001B[1;34m(g, *args, **kwargs)\u001B[0m\n\u001B[0;32m    463\u001B[0m         is_quantized\u001B[38;5;241m.\u001B[39mappend(_is_arg_quantized(descriptor, arg))\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(is_quantized):\n\u001B[1;32m--> 466\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(g, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    468\u001B[0m \u001B[38;5;66;03m# Dequantize arguments that are quantized\u001B[39;00m\n\u001B[0;32m    469\u001B[0m non_quantized_args \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\symbolic_opset9.py:1695\u001B[0m, in \u001B[0;36m_adaptive_pool.<locals>.symbolic_fn\u001B[1;34m(g, input, output_size)\u001B[0m\n\u001B[0;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_size \u001B[38;5;241m==\u001B[39m [\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(output_size):\n\u001B[0;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m g\u001B[38;5;241m.\u001B[39mop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGlobalMaxPool\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m), \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1695\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msymbolic_helper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unimplemented\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput size not accessible\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\n\u001B[0;32m   1697\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1698\u001B[0m \u001B[38;5;66;03m# verify if output size % input size = 0 for all dim\u001B[39;00m\n\u001B[0;32m   1699\u001B[0m mod \u001B[38;5;241m=\u001B[39m [dim[i] \u001B[38;5;241m%\u001B[39m output_size[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(dim))]\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\symbolic_helper.py:657\u001B[0m, in \u001B[0;36m_unimplemented\u001B[1;34m(op, msg, value)\u001B[0m\n\u001B[0;32m    654\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_unimplemented\u001B[39m(op: \u001B[38;5;28mstr\u001B[39m, msg: \u001B[38;5;28mstr\u001B[39m, value: _C\u001B[38;5;241m.\u001B[39mValue \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    655\u001B[0m     \u001B[38;5;66;03m# For BC reasons, the behavior for Caffe2 does not raise exception for unimplemented operators\u001B[39;00m\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m GLOBALS\u001B[38;5;241m.\u001B[39moperator_export_type \u001B[38;5;241m==\u001B[39m _C_onnx\u001B[38;5;241m.\u001B[39mOperatorExportTypes\u001B[38;5;241m.\u001B[39mONNX:\n\u001B[1;32m--> 657\u001B[0m         \u001B[43m_onnx_unsupported\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mop\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m, \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmsg\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\symbolic_helper.py:667\u001B[0m, in \u001B[0;36m_onnx_unsupported\u001B[1;34m(op_name, value)\u001B[0m\n\u001B[0;32m    661\u001B[0m message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    662\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported: ONNX export of operator \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mop_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    663\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease feel free to request support or submit a pull request \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon PyTorch GitHub: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_constants\u001B[38;5;241m.\u001B[39mPYTORCH_GITHUB_ISSUES_URL\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    665\u001B[0m )\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, _C\u001B[38;5;241m.\u001B[39mValue):\n\u001B[1;32m--> 667\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mSymbolicValueError(\n\u001B[0;32m    668\u001B[0m         message,\n\u001B[0;32m    669\u001B[0m         value,\n\u001B[0;32m    670\u001B[0m     )\n\u001B[0;32m    671\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOnnxExporterError(message)\n",
      "\u001B[1;31mSymbolicValueError\u001B[0m: Unsupported: ONNX export of operator adaptive_avg_pool2d, input size not accessible. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues  [Caused by the value 'input.4 defined in (%input.4 : Float(*, 16, *, *, strides=[250000, 15625, 125, 1], requires_grad=0, device=cpu) = onnx::Relu(%19), scope: __main__.SimpleNN:: # D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1697:0\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Relu'.] \n    (node defined in D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\functional.py(1697): relu\nC:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\666256591.py(20): forward\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1765): _slow_forward\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1786): _call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1775): _wrapped_call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\jit\\_trace.py(129): wrapper\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\jit\\_trace.py(138): forward\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1786): _call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py(1775): _wrapped_call_impl\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\jit\\_trace.py(1403): _get_trace_graph\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(898): _trace_and_get_graph_from_model\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(991): _create_jit_graph\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(1107): _model_to_graph\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(1507): _export\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py(549): export\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\onnx\\__init__.py(343): export\nC:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\3476701642.py(5): export_onnx\nC:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_20084\\1986237680.py(2): <module>\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3579): run_code\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3519): run_ast_nodes\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3336): run_cell_async\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py(128): _pseudo_sync_runner\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3132): _run_cell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3077): run_cell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py(577): run_cell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py(455): do_execute\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(767): execute_request\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py(368): execute_request\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(400): dispatch_shell\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(508): process_one\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py(519): dispatch_queue\nC:\\Program Files\\Python310\\lib\\asyncio\\events.py(80): _run\nC:\\Program Files\\Python310\\lib\\asyncio\\base_events.py(1881): _run_once\nC:\\Program Files\\Python310\\lib\\asyncio\\base_events.py(595): run_forever\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py(211): start\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py(739): start\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\nD:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\ipykernel_launcher.py(18): <module>\nC:\\Program Files\\Python310\\lib\\runpy.py(86): _run_code\nC:\\Program Files\\Python310\\lib\\runpy.py(196): _run_module_as_main\n)\n\n    Inputs:\n        #0: 19 defined in (%19 : Float(*, 16, *, *, strides=[250000, 15625, 125, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%input, %conv2.weight, %conv2.bias), scope: __main__.SimpleNN::/torch.nn.modules.conv.Conv2d::conv2 # D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:543:0\n    )  (type 'Tensor')\n    Outputs:\n        #0: input.4 defined in (%input.4 : Float(*, 16, *, *, strides=[250000, 15625, 125, 1], requires_grad=0, device=cpu) = onnx::Relu(%19), scope: __main__.SimpleNN:: # D:\\programming\\python\\2025-NN-AI\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1697:0\n    )  (type 'Tensor')"
     ]
    }
   ],
   "source": [
    "onnx_path = \"model.onnx\"\n",
    "export_onnx(model, onnx_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:01:20.772970Z",
     "end_time": "2026-02-11T20:01:20.818965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)  # Check for model correctness\n",
    "\n",
    "print(\"Model inputs:\")\n",
    "for input in onnx_model.graph.input:\n",
    "    print(f\"Input name: {input.name}\")\n",
    "    print(\n",
    "        f\"Input shape: {[(d.dim_value if d.HasField('dim_value') else d.dim_param) for d in input.type.tensor_type.shape.dim]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:01:20.820958Z",
     "end_time": "2026-02-11T20:01:20.831961Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take a look at model graph\n",
    "# https://netron.app/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-11T20:01:20.833962Z",
     "end_time": "2026-02-11T20:01:20.874960Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
