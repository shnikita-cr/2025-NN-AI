{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:23.529531Z",
     "end_time": "2026-02-18T18:29:32.693571Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 1. Configuration and Data Loading\n",
    "BATCH_SIZE = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize with MNIST mean (0.1307) and std (0.3081)\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.671575Z",
     "end_time": "2026-02-18T18:29:32.704576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Download and load training data\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Download and load test data\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.693571Z",
     "end_time": "2026-02-18T18:29:32.883199Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.824684Z",
     "end_time": "2026-02-18T18:29:32.957944Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 2. Define the Neural Network Model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)  #26 26\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)  # 13 13\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)  #11 11\n",
    "        # self.pool2 = nn.AdaptiveAvgPool2d(output_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.fc3 = nn.Linear(16 * 3 * 3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input image from 28x28 to a 784-element vector\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 16 * 3 * 3)\n",
    "        x = self.fc3(x)\n",
    "        # Apply log softmax for the final output (often used with NLLLoss, which is part of CrossEntropyLoss)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = SimpleNN().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.862670Z",
     "end_time": "2026-02-18T18:29:32.965080Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 3. Define Loss and Optimizer\n",
    "criterion = nn.NLLLoss()  # Negative Log-Likelihood Loss (suitable for log_softmax output)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.885195Z",
     "end_time": "2026-02-18T18:29:32.974372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nSimpleNN                                 --\n├─Conv2d: 1-1                            80\n├─MaxPool2d: 1-2                         --\n├─Conv2d: 1-3                            1,168\n├─MaxPool2d: 1-4                         --\n├─Linear: 1-5                            1,450\n=================================================================\nTotal params: 2,698\nTrainable params: 2,698\nNon-trainable params: 0\n================================================================="
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.899576Z",
     "end_time": "2026-02-18T18:29:33.151228Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "writer = SummaryWriter(f'runs/init_{datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.932276Z",
     "end_time": "2026-02-18T18:29:33.158373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 2.353880\n",
      "Train Epoch: 1/5 [6400/60000 (11%)]\tLoss: 0.605367\n",
      "Train Epoch: 1/5 [12800/60000 (21%)]\tLoss: 0.189975\n",
      "Train Epoch: 1/5 [19200/60000 (32%)]\tLoss: 0.306724\n",
      "Train Epoch: 1/5 [25600/60000 (43%)]\tLoss: 0.299493\n",
      "Train Epoch: 1/5 [32000/60000 (53%)]\tLoss: 0.156264\n",
      "Train Epoch: 1/5 [38400/60000 (64%)]\tLoss: 0.255736\n",
      "Train Epoch: 1/5 [44800/60000 (75%)]\tLoss: 0.227101\n",
      "Train Epoch: 1/5 [51200/60000 (85%)]\tLoss: 0.031764\n",
      "Train Epoch: 1/5 [57600/60000 (96%)]\tLoss: 0.095282\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.346507\n",
      "Train Epoch: 2/5 [6400/60000 (11%)]\tLoss: 0.047977\n",
      "Train Epoch: 2/5 [12800/60000 (21%)]\tLoss: 0.100386\n",
      "Train Epoch: 2/5 [19200/60000 (32%)]\tLoss: 0.013483\n",
      "Train Epoch: 2/5 [25600/60000 (43%)]\tLoss: 0.097030\n",
      "Train Epoch: 2/5 [32000/60000 (53%)]\tLoss: 0.095211\n",
      "Train Epoch: 2/5 [38400/60000 (64%)]\tLoss: 0.090845\n",
      "Train Epoch: 2/5 [44800/60000 (75%)]\tLoss: 0.195904\n",
      "Train Epoch: 2/5 [51200/60000 (85%)]\tLoss: 0.130863\n",
      "Train Epoch: 2/5 [57600/60000 (96%)]\tLoss: 0.036001\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.177926\n",
      "Train Epoch: 3/5 [6400/60000 (11%)]\tLoss: 0.128410\n",
      "Train Epoch: 3/5 [12800/60000 (21%)]\tLoss: 0.033541\n",
      "Train Epoch: 3/5 [19200/60000 (32%)]\tLoss: 0.110752\n",
      "Train Epoch: 3/5 [25600/60000 (43%)]\tLoss: 0.090648\n",
      "Train Epoch: 3/5 [32000/60000 (53%)]\tLoss: 0.047975\n",
      "Train Epoch: 3/5 [38400/60000 (64%)]\tLoss: 0.103674\n",
      "Train Epoch: 3/5 [44800/60000 (75%)]\tLoss: 0.157436\n",
      "Train Epoch: 3/5 [51200/60000 (85%)]\tLoss: 0.128809\n",
      "Train Epoch: 3/5 [57600/60000 (96%)]\tLoss: 0.217041\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.080870\n",
      "Train Epoch: 4/5 [6400/60000 (11%)]\tLoss: 0.297538\n",
      "Train Epoch: 4/5 [12800/60000 (21%)]\tLoss: 0.092153\n",
      "Train Epoch: 4/5 [19200/60000 (32%)]\tLoss: 0.066496\n",
      "Train Epoch: 4/5 [25600/60000 (43%)]\tLoss: 0.004117\n",
      "Train Epoch: 4/5 [32000/60000 (53%)]\tLoss: 0.102243\n",
      "Train Epoch: 4/5 [38400/60000 (64%)]\tLoss: 0.036096\n",
      "Train Epoch: 4/5 [44800/60000 (75%)]\tLoss: 0.009140\n",
      "Train Epoch: 4/5 [51200/60000 (85%)]\tLoss: 0.027890\n",
      "Train Epoch: 4/5 [57600/60000 (96%)]\tLoss: 0.010027\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.042348\n",
      "Train Epoch: 5/5 [6400/60000 (11%)]\tLoss: 0.050928\n",
      "Train Epoch: 5/5 [12800/60000 (21%)]\tLoss: 0.117868\n",
      "Train Epoch: 5/5 [19200/60000 (32%)]\tLoss: 0.030185\n",
      "Train Epoch: 5/5 [25600/60000 (43%)]\tLoss: 0.041494\n",
      "Train Epoch: 5/5 [32000/60000 (53%)]\tLoss: 0.019314\n",
      "Train Epoch: 5/5 [38400/60000 (64%)]\tLoss: 0.015604\n",
      "Train Epoch: 5/5 [44800/60000 (75%)]\tLoss: 0.028885\n",
      "Train Epoch: 5/5 [51200/60000 (85%)]\tLoss: 0.023549\n",
      "Train Epoch: 5/5 [57600/60000 (96%)]\tLoss: 0.018851\n"
     ]
    }
   ],
   "source": [
    "# 4. Training Loop\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = criterion(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass (calculate gradients)\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch + 1}/{NUM_EPOCHS} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:29:32.945699Z",
     "end_time": "2026-02-18T18:32:23.845392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleNN(\n  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n  (fc3): Linear(in_features=144, out_features=10, bias=True)\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:23.843306Z",
     "end_time": "2026-02-18T18:32:23.865738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleNN(\n  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n  (fc3): Linear(in_features=144, out_features=10, bias=True)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:23.861037Z",
     "end_time": "2026-02-18T18:32:23.916812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# tensorboard --logdir=runs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:23.875930Z",
     "end_time": "2026-02-18T18:32:23.916812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0588, Accuracy: 9823/10000 (98.23%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Testing the Model\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "      f'({accuracy:.2f}%)\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:23.894306Z",
     "end_time": "2026-02-18T18:32:28.356742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('conv1.weight',\n              tensor([[[[-0.4814, -0.6990, -0.7116],\n                        [ 0.4219,  0.0650, -0.0044],\n                        [ 0.5095,  0.2138,  0.7075]]],\n              \n              \n                      [[[-0.2946,  0.3478,  0.4269],\n                        [-0.2358, -0.0920,  0.4480],\n                        [-0.0642, -0.5702,  0.1428]]],\n              \n              \n                      [[[-0.5580, -0.1553,  0.1899],\n                        [-0.3164, -0.4126, -0.4613],\n                        [-0.4651, -0.1684, -0.6459]]],\n              \n              \n                      [[[-0.1388, -0.6455,  0.0852],\n                        [ 0.4127, -0.3864, -0.5679],\n                        [ 0.5861,  0.2225, -0.3083]]],\n              \n              \n                      [[[ 0.1478, -0.0027,  0.4175],\n                        [-0.1326,  0.1175,  0.3983],\n                        [-0.5018, -0.1197,  0.2888]]],\n              \n              \n                      [[[-0.6506, -0.0435,  0.3001],\n                        [-0.2775,  0.4871,  0.4074],\n                        [ 0.4712,  0.1592,  0.2863]]],\n              \n              \n                      [[[ 0.1957,  0.2832,  0.2407],\n                        [ 0.0060,  0.1798,  0.2064],\n                        [ 0.3160,  0.0424,  0.3778]]],\n              \n              \n                      [[[ 0.4608, -0.0039, -0.6004],\n                        [ 0.1192,  0.4361,  0.3098],\n                        [-0.0489,  0.3261,  0.4151]]]])),\n             ('conv1.bias',\n              tensor([0.0196, 0.0357, 0.5558, 0.1331, 0.2485, 0.4790, 0.4749, 0.4225])),\n             ('conv2.weight',\n              tensor([[[[ 1.9356e-01,  1.5682e-01,  2.5023e-02],\n                        [ 3.0990e-02,  7.4019e-02,  2.1902e-01],\n                        [ 8.4994e-02, -2.0946e-02, -7.9403e-02]],\n              \n                       [[ 1.7461e-01,  1.4102e-01,  1.5527e-01],\n                        [-1.4340e-01, -2.2751e-01, -2.9597e-01],\n                        [-4.0392e-01, -5.5395e-02, -1.9564e-02]],\n              \n                       [[-1.0283e-03,  9.0086e-02,  2.0910e-01],\n                        [ 1.1266e-01, -7.7580e-02,  1.0389e-01],\n                        [-1.9313e-01, -1.4409e-01,  6.5031e-03]],\n              \n                       ...,\n              \n                       [[-1.3543e-02, -1.1412e-01, -1.7616e-01],\n                        [-3.1850e-02,  8.3634e-02,  1.4257e-01],\n                        [ 2.2678e-01,  1.2974e-01,  1.4494e-01]],\n              \n                       [[-3.7583e-02, -9.8421e-02,  8.7117e-02],\n                        [-1.7336e-01, -8.8969e-04, -1.4969e-01],\n                        [ 2.3684e-02, -1.8735e-02,  3.5528e-02]],\n              \n                       [[-4.5999e-03,  5.4126e-02, -5.4947e-02],\n                        [-5.0138e-02, -6.3605e-02,  1.4550e-01],\n                        [ 1.3191e-01,  1.2864e-01,  1.0864e-01]]],\n              \n              \n                      [[[-1.0584e-01, -2.7113e-02, -1.0177e-01],\n                        [ 6.6169e-02, -1.8760e-01, -1.6606e-01],\n                        [-1.2419e-01, -2.9081e-01, -1.6146e-01]],\n              \n                       [[ 9.0703e-02, -3.3244e-01,  6.2726e-02],\n                        [-1.4230e-01,  2.5111e-02, -1.0462e-01],\n                        [ 1.8588e-01,  2.8972e-02, -1.7895e-01]],\n              \n                       [[ 1.5899e-01,  8.0960e-03,  6.9045e-02],\n                        [ 2.1308e-02, -5.3064e-02, -1.5590e-01],\n                        [-5.3621e-02, -5.2574e-02,  2.5819e-02]],\n              \n                       ...,\n              \n                       [[-8.4335e-02,  1.7406e-01,  3.6944e-01],\n                        [ 2.2002e-01,  3.3810e-01,  9.2662e-02],\n                        [ 3.4659e-01,  9.2955e-02, -1.7477e-01]],\n              \n                       [[-4.3517e-04, -7.9279e-02,  1.4561e-01],\n                        [-7.4022e-02,  1.2991e-01,  2.0288e-01],\n                        [ 1.7244e-01,  1.2247e-01, -1.4085e-01]],\n              \n                       [[-8.0050e-02, -8.4068e-02,  5.0534e-02],\n                        [-1.3413e-01,  1.3644e-01, -5.2431e-02],\n                        [ 1.8846e-01,  1.9068e-01, -5.7074e-02]]],\n              \n              \n                      [[[-1.5831e-01, -1.0887e-01,  3.5674e-01],\n                        [ 1.3888e-01, -2.8714e-01, -3.0146e-01],\n                        [ 2.5658e-01,  3.7706e-01, -3.4076e-01]],\n              \n                       [[ 1.1620e-01,  2.9278e-01, -2.8193e-01],\n                        [-9.7428e-02,  1.4877e-01,  3.3549e-01],\n                        [-7.7870e-02, -1.1163e-01,  7.3189e-02]],\n              \n                       [[-2.6658e-01, -4.0852e-01, -1.8684e-01],\n                        [-6.6209e-02, -1.5683e-01, -2.3816e-01],\n                        [-1.2148e-01, -3.5561e-01, -3.3077e-01]],\n              \n                       ...,\n              \n                       [[-2.7596e-02,  7.4393e-02, -2.0169e-01],\n                        [-5.0556e-02, -1.0487e-01, -1.2880e-02],\n                        [ 7.4001e-02,  1.0742e-01,  1.9702e-01]],\n              \n                       [[ 3.8875e-02,  2.3985e-02, -1.8126e-02],\n                        [ 2.1584e-02, -3.7332e-02,  1.6129e-01],\n                        [-1.9389e-01, -1.2032e-01,  7.9901e-02]],\n              \n                       [[ 1.5637e-01,  1.5096e-01,  1.9442e-01],\n                        [-3.9930e-02, -1.3937e-01,  2.4471e-01],\n                        [-1.8588e-02, -4.1361e-02, -1.1738e-01]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-2.9125e-01,  1.3153e-01,  8.0654e-02],\n                        [-1.7486e-01, -2.9588e-01, -1.1857e-01],\n                        [-1.4618e-01, -3.9770e-01, -9.3565e-02]],\n              \n                       [[ 1.4332e-01,  9.4530e-02,  1.0212e-01],\n                        [ 1.3565e-01,  9.2148e-02, -2.7590e-01],\n                        [ 1.4059e-01,  3.1301e-02, -4.0519e-02]],\n              \n                       [[-2.6865e-02, -1.2803e-01, -8.4371e-02],\n                        [-1.1678e-01, -2.3960e-01,  3.3750e-02],\n                        [-4.8081e-02, -5.1017e-01, -1.8756e-01]],\n              \n                       ...,\n              \n                       [[ 1.8852e-02, -1.2258e-01, -2.4442e-01],\n                        [-1.5154e-02, -3.3964e-03, -1.6688e-01],\n                        [ 2.3104e-01,  1.7324e-01,  5.2266e-03]],\n              \n                       [[-2.6233e-03,  1.2850e-01, -1.7198e-01],\n                        [-1.1375e-01,  4.2394e-02,  4.9082e-02],\n                        [ 1.0546e-01,  1.1830e-01, -5.6938e-02]],\n              \n                       [[ 8.8607e-02,  1.2343e-01, -4.9327e-02],\n                        [-1.4871e-01,  1.4739e-01, -1.0481e-01],\n                        [ 8.1500e-02,  2.6170e-01,  2.6593e-02]]],\n              \n              \n                      [[[-8.0213e-02,  2.1886e-03,  5.8810e-02],\n                        [ 4.0689e-02, -2.2847e-02, -2.2078e-01],\n                        [ 1.8321e-01,  2.0052e-01,  6.5629e-02]],\n              \n                       [[-8.8451e-02, -6.6513e-02,  1.3293e-01],\n                        [ 2.4096e-02, -4.0520e-02,  8.6443e-02],\n                        [-6.3520e-02, -4.5113e-01,  9.9078e-02]],\n              \n                       [[ 5.0804e-02,  2.8127e-02, -9.3826e-02],\n                        [ 6.1679e-02,  1.1922e-01,  1.4791e-01],\n                        [ 3.7393e-02,  6.4983e-02,  1.6712e-01]],\n              \n                       ...,\n              \n                       [[-1.8900e-01,  3.6502e-02,  2.3442e-01],\n                        [-1.3654e-01, -1.7219e-01, -9.9294e-02],\n                        [ 1.5172e-01, -4.9987e-02, -1.5595e-01]],\n              \n                       [[-2.4240e-01, -1.4336e-01,  9.6746e-02],\n                        [-1.9142e-01, -6.4234e-02,  3.5917e-02],\n                        [ 3.3145e-02, -1.6874e-01, -6.7651e-02]],\n              \n                       [[-4.7521e-02, -9.1010e-02, -4.9649e-02],\n                        [-9.8386e-02, -1.9095e-01, -3.0652e-01],\n                        [ 5.0983e-02, -4.8693e-02, -2.5426e-01]]],\n              \n              \n                      [[[-1.7407e-01, -6.9910e-02,  1.0791e-02],\n                        [-1.0604e-01, -1.1554e-02,  2.4413e-01],\n                        [ 1.7321e-01, -1.2949e-01,  2.6816e-01]],\n              \n                       [[ 1.4186e-01,  7.5742e-02,  1.4350e-01],\n                        [ 3.1244e-01,  3.2101e-01,  1.7454e-01],\n                        [ 1.9519e-01,  2.1417e-01,  1.7835e-01]],\n              \n                       [[-2.2455e-01, -2.9996e-01, -2.5025e-01],\n                        [-6.2844e-02, -2.8666e-01, -1.8770e-01],\n                        [-1.5479e-03, -1.2787e-01, -1.7365e-01]],\n              \n                       ...,\n              \n                       [[ 1.3209e-02, -1.7271e-01, -7.1136e-02],\n                        [-4.1509e-02, -1.9167e-02, -1.8887e-01],\n                        [-2.4408e-01, -5.6167e-02, -1.2816e-01]],\n              \n                       [[ 7.6940e-02, -1.4840e-01, -1.2905e-01],\n                        [ 6.1281e-02, -7.1838e-03, -7.8428e-02],\n                        [-3.1655e-01, -7.9690e-02,  1.1936e-01]],\n              \n                       [[ 1.9015e-01,  5.2873e-02,  3.3081e-02],\n                        [-4.0397e-02,  1.6439e-01,  1.2246e-01],\n                        [-2.8191e-01,  8.2109e-02,  2.2172e-01]]]])),\n             ('conv2.bias',\n              tensor([ 0.1135,  0.1565,  0.0317, -0.0364,  0.0838, -0.0860, -0.0755, -0.1060,\n                      -0.0099, -0.0290, -0.0194,  0.0034,  0.0360, -0.0414,  0.1020,  0.0414])),\n             ('fc3.weight',\n              tensor([[-0.1061,  0.1357, -0.0108,  ..., -0.0076,  0.0801, -0.0965],\n                      [ 0.0671, -0.0296, -0.0350,  ..., -0.0427, -0.1644,  0.0617],\n                      [ 0.0615, -0.0509, -0.0470,  ..., -0.0301, -0.0192,  0.1120],\n                      ...,\n                      [-0.0230,  0.0639,  0.1328,  ..., -0.2265, -0.0750, -0.0986],\n                      [ 0.0517, -0.0294,  0.0361,  ...,  0.0657, -0.0351,  0.1118],\n                      [ 0.0083,  0.1616,  0.0101,  ...,  0.0385, -0.0483, -0.0205]])),\n             ('fc3.bias',\n              tensor([ 0.1099, -0.0055,  0.0977, -0.0571, -0.0056, -0.0365, -0.0135, -0.0896,\n                       0.0430, -0.0243]))])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:33:03.677401Z",
     "end_time": "2026-02-18T18:33:03.766596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Save the model (optional)\n",
    "torch.save(model.state_dict(), \"mnist_simple_nn.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:28.364842Z",
     "end_time": "2026-02-18T18:32:28.410175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:28.399984Z",
     "end_time": "2026-02-18T18:32:28.410175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def export_onnx(model, onnx_path=\"dynamic_cnn.onnx\"):\n",
    "    dummy = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy,\n",
    "            onnx_path,\n",
    "            opset_version=18,\n",
    "            dynamo=False,\n",
    "            export_params=True,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"output\"],\n",
    "            dynamic_axes={\n",
    "                \"input\": {0: \"batch\", 2: \"height\", 3: \"width\"},\n",
    "                \"output\": {0: \"batch\"},\n",
    "            },\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:28.418255Z",
     "end_time": "2026-02-18T18:32:28.430542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_7788\\1920309358.py:5: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "onnx_path = \"model.onnx\"\n",
    "export_onnx(model, onnx_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:28.438633Z",
     "end_time": "2026-02-18T18:32:28.691435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inputs:\n",
      "Input name: input\n",
      "Input shape: ['batch', 1, 'height', 'width']\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)  # Check for model correctness\n",
    "\n",
    "print(\"Model inputs:\")\n",
    "for input in onnx_model.graph.input:\n",
    "    print(f\"Input name: {input.name}\")\n",
    "    print(\n",
    "        f\"Input shape: {[(d.dim_value if d.HasField('dim_value') else d.dim_param) for d in input.type.tensor_type.shape.dim]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:28.691435Z",
     "end_time": "2026-02-18T18:32:28.767867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Take a look at model graph\n",
    "# https://netron.app/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2026-02-18T18:32:28.767867Z",
     "end_time": "2026-02-18T18:32:28.776859Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
